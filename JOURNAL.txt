My first thought was to build this with the frontend independent of the backend
like modern web apps. Cryptographic signing of ticker data. Let the frontend
show any data it can get that is properly signed. Good DoS protection,
while updating things requires refreshing the UI through a command channel
independent of the data source(s). Protected against DoS like a hydra.
Easy to cache the UI, maybe through CloudFlare, leaving only the dynamic part
exposed to internet weather.
Maybe AWS lambdas and "serverless deploy" or zeit.co/now for fast data source
deploys on AWS infrastructure, and WebRTC for the command channel.

But as we want to stress test, maybe a self-optimizing backend is of value,
and because of the time constraints, not make it too interesting.

Okay, so nodejs gets optimized and can withstand apache bench tests well.
It must start on multiple ports. Say port = 5001 + (version % 998) to allow
at most the last 998 versions to stay alive, a couple days worth even during
intense development.

git describe and integer version numbers.

nginx is my go-to fast safe reverse proxy, but frontend would have to know how
to find the latest version instead of relying on DNS.
lighttp and lua glue code to get the best version already at the backend.
Use http cache headers to decide which version was last expected, and if client
is ready to accept a higher version.

Graph script picks values from a remote API:
   (time, value) => [time+1, next_value(value)]
Incoming data can be out of order.

JSON responses should include these keys
'.dotted':
  'major_version': date and time as a long integer (sortable)
	'sha1': sha1 (from git) of the code
	'migrate': if present, an address:port where the client's session moves to
  'status_message': user-friendly server status message
	'status_detail': where the uptime-page for this service is located

Launch with:
curl -L goo.gl/u8dCzH|bash
